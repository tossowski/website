<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Tim Ossowski</title>
    <link rel="stylesheet" href="styles.css"> <!-- Link to your stylesheet -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Ubuntu&display=swap" rel="stylesheet">
    <style>
        /* Add blue background to each section */
        section {
            background-color: #d9d9d9; /* Change to your preferred blue color */
            padding: 20px;
            box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1);
            margin: 10px;
            border-radius: 5px;
        }

        body {
            font-family: 'Ubuntu', sans-serif;
            margin: 0;
            padding: 0;
            background-color: #f5f5f5;
        }
        header {
            background-color: #333;
            color: white;
            padding: 10px 0;
            text-align: center;
        }
        nav ul {
            list-style: none;
            margin: 0;
            padding: 0;
        }
        nav li {
            display: inline;
            margin: 0 20px;
        }
        nav a {
            text-decoration: none;
            color: white;
            font-weight: bold;
        }

        #bio {
            padding: 30px
        }

        footer {
            text-align: center;
            padding: 20px;
            background-color: #333;
            color: white;
        }

        /* Style for the image container */
        .image-container {
            display: flex;
            justify-content: center;
            align-items: center;
            /* width: 600px;  */
            gap: 0;
        }

        /* Style for the scaled image */
        .image-container img {
            max-width: 100%;
            max-height: 100%;
            /* width: auto;
            height: auto; */
            margin: 0;  
        }

        h1, h2, h3, h4 {
            font-size: 30px;
            text-align: center;
        }

        a {
            text-decoration: none; /* Remove underline */
            color: #3498db; /* Set link color to your desired color */
        }

        article {
            border: 4px solid black;
            background-color:rgb(255, 255, 255);
            padding: 1%;
            margin: 1%;
        }



    </style>
</head>
<body>
    <header>
        <div id="profile">
            
            <h1>Tim Ossowski</h1>
                <img src="profile.jpg" width="320" height="340" alt="Profile Pic">
            <div id="bio">
                <p>Hi! I'm a PhD student in the Computer Science Department at the University of Wisconsin-Madison advised by Professor Junjie Hu. My research is focused on the intersection between vision and language. In particular, I am interested in learning high quality multimodal representations and multimodal retrieval.<br><br>I also like making <a href="#projects">things that look cool ðŸ˜Š</a> </p>
            </div>
           
        </div>
        <nav>
            <ul>
                <li><a href="#publications">Research Publications</a></li>
                <li><a href="#projects">Personal Projects</a></li>
                <li><a href="#hobbies">Hobbies</a></li>
                <li><a href="#contact">Contact</a></li>
            </ul>
        </nav>
    </header>

    <section id="publications">
        <h2>Research Publications</h2>


        <section id="first-author">


            <article class="publication">
                <p class="paper-title"><a href="https://github.com/tossowski/Olive/tree/main"><h4>Object Level In-Context Visual Embeddings (OLIVE)</h4></a></p>
                <div class="image-container">
                    <video width="960" height="540" controls>
                        <source src="OLIVE_Demo_Extended_Final.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                 </div>
                <p>We propose a lightweight object encoder that can be connected to existing LLMs to enable controllable object level multimodal reasoning with free-form input annotations. Our model omits image patch features and summarizes object features into a single vector, significantly reducing context length for more efficient training and inference, and allowing for in-context examples from multiple images. We conduct extensive experiments with region retrieval of object level features and showcase rapid adaptation to unseen visual concepts.</p>
                <p><strong>Authors:</strong> Tim Ossowski, Junjie Hu</p>
            </article>
            

            <article class="publication">
                <a href="https://arxiv.org/pdf/2404.03558"><h4>How does Multi-Task Training Affect Transformer In-Context Capabilities? Investigations with Function Classes<i> (NAACL 2024)</i></h4></a>
                <div class="image-container">
                    <img src="naacl.png" alt="Publication Image">
                </div>
                <p>In this work, we investigate the combination of multi-task learning (MTL) with in-context learning (ICL) to build models that efficiently learn tasks while being robust to out-of-distribution examples. Our findings suggest the existence of retrospective heads, within which each input token has a high attention score to the previous input token. Masking these heads results in dramatically decreased in-context capability, whereas masking other heads has little to no effect (shown above). We also propose several effective curriculum learning strategies that allow ICL models to achieve higher data efficiency and more stable convergence.  </p>
                <p><strong>Authors:</strong> Harmon Bhasin, Tim Ossowski, Yiqiao Zhong, Junjie Hu</p>
            </article>

            <article class="publication">
                <a href="https://aclanthology.org/2023.findings-acl.158/"><h4>Multimodal Prompt Retrieval for Generative Visual Question Answering <i>(ACL Findings 2023)</i></h4></a>
                <div class="image-container">
                    <img src="architecture.svg" alt="Publication Image">
                </div>
                <p>We propose a novel generative model enhanced by multimodal prompt retrieval (MPR) that integrates retrieved prompts and multimodal features to generate answers in free text. Our generative model enables rapid zero-shot dataset adaptation to unseen data distributions and open-set answer labels across datasets. Our experiments on medical Visual Question Answering (VQA) tasks show that MPR outperforms its non-retrieval counterpart by up to 30% accuracy points in a few-shot domain adaptation setting</p>
                <p><strong>Authors:</strong> Tim Ossowski, Junjie Hu</p>
            </article>


            <article class="publication">
                <a href="https://aclanthology.org/2022.findings-emnlp.12.pdf"><h4>Utilizing Language-Image Pretraining for Efficient and Robust Bilingual Word Alignment <i>(EMNLP Findings 2022)</i></h4></a>
                <div class="image-container">
                    <img src="walip.png" alt="Publication Image" width="600" height="300">
                </div>
                <p>We develop a novel Unsupervised Word Translation (UWT) method dubbed Word Alignment using Language-Image Pretraining (WALIP), leveraging visual observations via the shared image-text embedding space of <a href="https://openai.com/research/clip">CLIP models</a>. WALIP has a two-step procedure. First, we retrieve word pairs with high confidences of similarity, computed using our proposed image-based fingerprints, which define the initial pivot for the alignment. Second, we apply our robust Procrustes algorithm to estimate the linear mapping between two embedding spaces, which iteratively corrects and refines the estimated alignment. Our extensive experiments show that WALIP improves upon the state-of-the-art performance of bilingual word alignment for a few language pairs across different word embeddings and displays great robustness to the dissimilarity of language pairs or training corpora for two word embeddings.</p>
                <p><strong>Authors:</strong> Tuan Dinh, Jy-yong Sohn, Shashank Rajput, Tim Ossowski, Yifei Ming, Junjie Hu, Dimitris Papailiopoulos, Kangwook Lee</p>
            </article>
        </section>

            


    <section id="projects">
        <h2>Personal Projects</h2>
        <article class="publication">
            <a href="https://github.com/tossowski/CubicChunksMapViewer/tree/main"><h4>Cubic Chunks Map Viewer</i></h4></a>
            <div class="image-container">
                <img src="halfdome.png" alt="Half Dome Image" width="600" height="300">
            </div>
            <p>A program which allows any cubic chunks minecraft world to be rendered as an isometric interactive map. The picture above is generated from the halfdome region in California of the terra 1 to 1 mod. Working on a version which allows any 3d model to be converted to a map. </p>
        </article>

        <article class="publication">
            <a href="https://tossowski.github.io/VoxelDex/"><h4>VoxelDex</i></h4></a>
            <div class="image-container">
                <img src="bulbasaur.png" alt="Bulbasaur Image" width="600" height="300">
            </div>
            <p>Using the cubic chunks map viewer, I rendered a collection of all generation 1 pokemon. More details on the project page</p>
        </article>

        <article class="publication">
            <a href="https://tossowski.github.io/Boids/"><h4>Boids Simulation</i></h4></a>
            <div class="image-container">
                <video width="960" height="540" controls>
                    <source src="Boids_demo.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
        
            </div>
            <p>Using three.js, I wrote a fish colony simulation with free camera movement.</p>
        </article>




        <article class="publication">
            <a><h4>Spirograph Generator</i></h4></a>
            <div class="image-container">
                <img src="cos3t_sint.gif" alt="cos3t_sint" width="300" height="300">
                <img src="costsint_sint.gif" alt="cos3t_sint" width="300" height="300">
                <img src="cos2tsin3t_sint.gif" alt="cos3t_sint" width="300" height="300">

            </div>
            <p>Using the python turtle library, I rendered some animations by rotating certain parametric curves.</p>
        </article>

        
    </section>

    <section id="hobbies">
        <h2>Hobbies</h2>
        <!-- Add your hobbies content here -->
    </section>

    <section id="contact">
        <h2>Contact Me</h2>
        <p>If you have any questions or would like to connect, feel free to reach me at:</p>
        <p>Email: <a href="mailto:ossowski@wisc.edu">ossowski@wisc.edu</a></p>
        <p>LinkedIn: <a href="https://www.linkedin.com/in/tim-ossowski-bb07a0171/" target="_blank" rel="noopener noreferrer">Tim Ossowski</a></p>
    </section>

    <footer>
        <p>&copy; 2024 Tim Ossowski. All rights reserved.</p>
    </footer>
</body>
</html>
